{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a368b35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports generales para trabajar con SQL y modelos\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "from getpass import getpass\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Imports para ir guardando y leyendo los modelos en la ruta ./Modelos\n",
    "from os import listdir\n",
    "import pickle, datetime, os, glob\n",
    "from pathlib import Path\n",
    "\n",
    "# Función de auxiliares\n",
    "from helpers import *\n",
    "\n",
    "# Modelos\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9180ba2",
   "metadata": {},
   "source": [
    "# Parte 1: Registro de los archivos en la base de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc264754",
   "metadata": {},
   "source": [
    "### Preparación de la base de datos\n",
    "A través de Dbeaver ya se generó la database hoffmann_jorge. Debemos conectarnos a ella, de modo que primero almacenamos los datos y generamos la conexión. A posteriori, se preparan las querys de creación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ccc96ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Introducir contraseña········\n"
     ]
    }
   ],
   "source": [
    "# Almacenamos los datos de conexión\n",
    "db_name = \"hoffmann_jorge\"\n",
    "host = \"localhost\"\n",
    "user = \"postgres\"\n",
    "password = getpass(\"Introducir contraseña\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bd74fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos nuestro objeto conexión\n",
    "conn = psycopg2.connect(f\"dbname={db_name} user={user} password={password}\")\n",
    "\n",
    "# Se crea cursor\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c6de329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el dataframe con el objetivo de extraer sus columnas\n",
    "df_train = pd.read_csv('train_cupid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdb19ed8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Escribimos la query que nos permitirá crear la tabla en la DB\n",
    "query_create_table_train = \"CREATE TABLE train_cupid(\"\n",
    "query_create_table_test = \"CREATE TABLE test_cupid(\"\n",
    "\n",
    "for col, tipo in zip(df_train.dtypes.index, df_train.dtypes):\n",
    "    # Reemplazamos espacios y el /.\n",
    "    col = col.replace(' / ', '').replace(' ', '')\n",
    "    # Para los tipos float63 e int64 los dejamos en float e int\n",
    "    tipo = tipo.name.replace('64', '')\n",
    "    aux = col + ' ' + tipo + ','\n",
    "    query_create_table_train = query_create_table_train + aux\n",
    "    query_create_table_test = query_create_table_test + aux\n",
    "    \n",
    "query_create_table_train = query_create_table_train[: -1] + \"); \"\n",
    "query_create_table_test = query_create_table_test[: -1] + \"); \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64fbd063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se ejecuta la query usando el cursor\n",
    "cur.execute(query_create_table_train)\n",
    "cur.execute(query_create_table_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e43af770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commiteamos los cambios\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9ce841",
   "metadata": {},
   "source": [
    "En este punto, ya generamos las tablas, lo siguiente es ingresar los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfa03e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_cupid.csv', 'r') as file:\n",
    "    # Se lee el contenido del archivo usando csv que permite iterar cada fila\n",
    "    reader = csv.reader(file)\n",
    "    # ignoramos la primera fila que corresponde al header\n",
    "    next(reader)\n",
    "    # para cada una de las filas remanentes\n",
    "    for row in reader:\n",
    "        # ejecutaremos una orden en el cursor que inserte los datos.\n",
    "        interpoladores = \"%s, \" * len(row)\n",
    "        cur.execute(f\"INSERT INTO train_cupid VALUES ({interpoladores[:-2]})\", row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cc9b201",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_cupid.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader)\n",
    "    # para cada una de las filas remanentes\n",
    "    for row in reader:\n",
    "        interpoladores = \"%s, \" * len(row)\n",
    "        cur.execute(f\"INSERT INTO test_cupid VALUES ({interpoladores[:-2]})\", row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7e5362d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfaf676",
   "metadata": {},
   "source": [
    "# Parte 2: Entrenamiento de modelos\n",
    "\n",
    "- Ingestar la tabla de training mediante psycopg2 para el posterior entrenamiento del\n",
    "modelo.\n",
    "- Entrenar los siguientes modelos (sin necesidad de ajustar por hiper parámetros): GradientBoostingClassifier, AdaBoostClassifer, RandomForestClassifier, SVC, DecisionTreeClassifier,\n",
    "LogisticRegression, BernoulliNB.\n",
    "- Existen tres vectores objetivos a evaluar: single, seeing someone y available. Serializar el objeto y preservarlo por cada combinación de modelo entrenado y vector\n",
    "objetivo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "651a2932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos nuestro objeto conexión nuevamente (lo cerramos anteriormente)\n",
    "conn = psycopg2.connect(f\"dbname={db_name} user={user} password={password}\")\n",
    "\n",
    "# Se crea cursor\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f15100fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>virgo</th>\n",
       "      <th>taurus</th>\n",
       "      <th>scorpio</th>\n",
       "      <th>pisces</th>\n",
       "      <th>libra</th>\n",
       "      <th>leo</th>\n",
       "      <th>gemini</th>\n",
       "      <th>aries</th>\n",
       "      <th>...</th>\n",
       "      <th>orientation_straight</th>\n",
       "      <th>sex_m</th>\n",
       "      <th>smokes_sometimes</th>\n",
       "      <th>smokes_tryingtoquit</th>\n",
       "      <th>smokes_whendrinking</th>\n",
       "      <th>smokes_yes</th>\n",
       "      <th>body_type_overweight</th>\n",
       "      <th>body_type_regular</th>\n",
       "      <th>education_high_school</th>\n",
       "      <th>education_undergrad_university</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  height  virgo  taurus  scorpio  pisces  libra  leo  gemini  aries  \\\n",
       "0   35    70.0      0       0        0       0      0    0       0      0   \n",
       "1   38    68.0      0       0        0       0      0    0       0      0   \n",
       "2   23    71.0      0       0        0       1      0    0       0      0   \n",
       "3   29    66.0      0       0        0       0      0    0       0      0   \n",
       "4   29    67.0      0       1        0       0      0    0       0      0   \n",
       "\n",
       "   ...  orientation_straight  sex_m  smokes_sometimes  smokes_tryingtoquit  \\\n",
       "0  ...                     1      1                 0                    0   \n",
       "1  ...                     1      1                 0                    0   \n",
       "2  ...                     1      1                 0                    0   \n",
       "3  ...                     1      1                 0                    0   \n",
       "4  ...                     1      1                 0                    0   \n",
       "\n",
       "   smokes_whendrinking  smokes_yes  body_type_overweight  body_type_regular  \\\n",
       "0                    0           0                     0                  1   \n",
       "1                    0           0                     0                  1   \n",
       "2                    0           0                     0                  1   \n",
       "3                    0           0                     0                  0   \n",
       "4                    0           0                     0                  1   \n",
       "\n",
       "   education_high_school  education_undergrad_university  \n",
       "0                      0                               0  \n",
       "1                      0                               0  \n",
       "2                      0                               1  \n",
       "3                      0                               1  \n",
       "4                      0                               1  \n",
       "\n",
       "[5 rows x 98 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generamos la consulta en el cursor\n",
    "cur.execute(\"SELECT * FROM train_cupid;\")\n",
    "\n",
    "# fetchall permite traer todo lo retornado por la consulta a una variable\n",
    "# Retorna una lista con tuplas\n",
    "datos = cur.fetchall()\n",
    "\n",
    "# Generamos DataFrame\n",
    "df_train = pd.DataFrame(datos)\n",
    "cur.execute(\"Select * FROM train_cupid LIMIT 0;\")\n",
    "columns = [desc[0] for desc in cur.description]\n",
    "df_train.columns = columns\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6326b06",
   "metadata": {},
   "source": [
    "Tenemos nuestros datos en el dataframe df_train obtenidos a través de psycopg2. El siguiente paso es entrenar los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66346a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos una lista de instancias de los modelos\n",
    "lista_modelos = [\n",
    "    GradientBoostingClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    LogisticRegression(),\n",
    "    BernoulliNB(),\n",
    "    DecisionTreeClassifier(),\n",
    "    SVC(probability = True)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7b1551",
   "metadata": {},
   "source": [
    "Función train_and_pickle (incluida en helpers.py)\n",
    "```python\n",
    "def train_and_pickle(model, X_train, y_train):\n",
    "    \"\"\"\n",
    "        Dado un modelo sklearn, además de X_train e y_train, se entrena el modelo\n",
    "        y luego se genera un archivo serializado con un nombre identificable.\n",
    "        \n",
    "        model: sklearn model class\n",
    "        X_train: matriz variables independientes\n",
    "        y_train: vector objetivo\n",
    "    \"\"\"\n",
    "    # Fiteo un modelo con X_train e y_train\n",
    "    tmp_model_train = model.fit(X_train, y_train)\n",
    "    # Extraigo el nombre del modelo\n",
    "    model_name = str(model.__class__).replace(\"'>\", '').split('.')[-1]\n",
    "    # El nombre del archivo debe ser el VectorObjetivo_Modelo.sav\n",
    "    nombre = f\"{y_train.name}_{model_name}.sav\"\n",
    "    # Se guardará en la ruta ./Modelos\n",
    "    path = Path(\"./Modelos\")  / nombre\n",
    "    pickle.dump(tmp_model_train, open(path, 'wb'))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6485f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos aseguramos de que X tenga toda la data salvo los 3 vectores objetivos\n",
    "X_train = df_train.copy()\n",
    "y_train_single = X_train.pop('single')\n",
    "y_train_seeing_someone = X_train.pop('seeing_someone')\n",
    "y_train_available = X_train.pop('available')\n",
    "\n",
    "# Generamos una lista con los vectores objetivo. \n",
    "lista_vectores_objetivo = [\n",
    "    y_train_single,\n",
    "    y_train_seeing_someone,\n",
    "    y_train_available\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf9c10c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jahof\\anaconda3\\envs\\py38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jahof\\anaconda3\\envs\\py38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jahof\\anaconda3\\envs\\py38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Generamos 21 modelos\n",
    "for modelo in lista_modelos:\n",
    "    for vector_objetivo in lista_vectores_objetivo:\n",
    "        train_and_pickle(modelo, X_train, vector_objetivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a10b92",
   "metadata": {},
   "source": [
    "# Parte 3: Exportación de predicciones\n",
    "Ingestar la tabla de testing mediante psycopg2 para la posterior predicción del\n",
    "modelo.  \n",
    "● En base a los objetos serializados, predecir y evaluar cuatro queries específicas:\n",
    "- Query 1: 'atheism', 'asian', 'employed', 'pro_dogs', 'chinese'.\n",
    "- Query 2: 'income_over_75', 'french', 'german','orientation_straight', 'new york'.\n",
    "- Query 3: 'education_undergrad_university', 'body_type_regular', 'pro_dogs','employed'.\n",
    "- Query 4: 'taurus', 'indian', 'washington', 'income_between_50_75', 'hinduism'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e437b5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>virgo</th>\n",
       "      <th>taurus</th>\n",
       "      <th>scorpio</th>\n",
       "      <th>pisces</th>\n",
       "      <th>libra</th>\n",
       "      <th>leo</th>\n",
       "      <th>gemini</th>\n",
       "      <th>aries</th>\n",
       "      <th>...</th>\n",
       "      <th>orientation_straight</th>\n",
       "      <th>sex_m</th>\n",
       "      <th>smokes_sometimes</th>\n",
       "      <th>smokes_tryingtoquit</th>\n",
       "      <th>smokes_whendrinking</th>\n",
       "      <th>smokes_yes</th>\n",
       "      <th>body_type_overweight</th>\n",
       "      <th>body_type_regular</th>\n",
       "      <th>education_high_school</th>\n",
       "      <th>education_undergrad_university</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  height  virgo  taurus  scorpio  pisces  libra  leo  gemini  aries  \\\n",
       "0   22    75.0      0       0        0       0      0    0       1      0   \n",
       "1   32    65.0      1       0        0       0      0    0       0      0   \n",
       "2   24    67.0      0       0        0       0      0    0       0      0   \n",
       "3   29    62.0      0       1        0       0      0    0       0      0   \n",
       "4   39    65.0      0       0        0       0      0    0       0      0   \n",
       "\n",
       "   ...  orientation_straight  sex_m  smokes_sometimes  smokes_tryingtoquit  \\\n",
       "0  ...                     1      1                 1                    0   \n",
       "1  ...                     1      0                 0                    0   \n",
       "2  ...                     1      0                 0                    0   \n",
       "3  ...                     1      0                 0                    0   \n",
       "4  ...                     1      0                 0                    0   \n",
       "\n",
       "   smokes_whendrinking  smokes_yes  body_type_overweight  body_type_regular  \\\n",
       "0                    0           0                     0                  0   \n",
       "1                    0           0                     0                  0   \n",
       "2                    1           0                     0                  0   \n",
       "3                    0           0                     0                  1   \n",
       "4                    0           0                     0                  0   \n",
       "\n",
       "   education_high_school  education_undergrad_university  \n",
       "0                      0                               1  \n",
       "1                      0                               1  \n",
       "2                      0                               1  \n",
       "3                      0                               1  \n",
       "4                      0                               1  \n",
       "\n",
       "[5 rows x 98 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generamos la consulta en el cursor\n",
    "cur.execute(\"SELECT * FROM test_cupid;\")\n",
    "\n",
    "# fetchall permite traer todo lo retornado por la consulta a una variable\n",
    "# Retorna una lista con tuplas\n",
    "datos = cur.fetchall()\n",
    "\n",
    "# Generamos DataFrame\n",
    "df_test = pd.DataFrame(datos)\n",
    "df_test.columns = columns\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66cea6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4827891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos aseguramos de que X tenga toda la data salvo los 3 vectores objetivos\n",
    "X_test = df_test.copy()\n",
    "y_test_single = X_test.pop('single')\n",
    "y_test_seeing_someone = X_test.pop('seeing_someone')\n",
    "y_test_available = X_test.pop('available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1eb00e75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['single_GradientBoostingClassifier.sav',\n",
       " 'seeing_someone_GradientBoostingClassifier.sav',\n",
       " 'available_GradientBoostingClassifier.sav',\n",
       " 'single_RandomForestClassifier.sav']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtengo una lista de todos los modelos guardados\n",
    "modelos_guardados = [modelo for modelo in listdir(Path(\"./Modelos\"))]\n",
    "modelos_guardados[: 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fc68fd",
   "metadata": {},
   "source": [
    "Función create_grouped_probabilty:\n",
    "\n",
    "```python\n",
    "def create_grouped_probabilty(model, X_test, vector_objetivo, variables):\n",
    "    \"\"\"Retorna un DataFrame agrupado por variables que para cada caso tiene la probabilidad\n",
    "    predicha para la variable de interés del modelo.\n",
    "    \n",
    "    model: sklearn model class\n",
    "    X_test: matriz de variables independientes\n",
    "    vector_objetivo: string que indica el nombre del vector objetivo\n",
    "    variables: lista de variables de X_test para el group by\n",
    "    \n",
    "    return:\n",
    "        DataFrame\n",
    "    \"\"\"\n",
    "    tmp = X_test.copy()\n",
    "    tmp_pr = model.predict_proba(X_test) \n",
    "\n",
    "    df_prob = pd.concat([\n",
    "        tmp.reset_index(drop = True), \n",
    "        pd.DataFrame(tmp_pr[:, 1], columns = [vector_objetivo])],\n",
    "        axis = 1)\n",
    "    \n",
    "    tmp_query = df_prob.groupby(variables)[vector_objetivo].mean()\n",
    "    return tmp_query\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31934573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos la lista de 'groups by' que necesitaremos más adelante\n",
    "lista_groups = [\n",
    "    ['atheism', 'asian', 'employed', 'pro_dogs', 'chinese'],\n",
    "    ['income_over_75', 'french', 'german','orientation_straight', 'newyork'],\n",
    "    ['education_undergrad_university', 'body_type_regular', 'pro_dogs','employed'],\n",
    "    ['taurus', 'indian', 'washington', 'income_between_50_75', 'hinduism']    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "846ead53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciamos engine para ingresar datos a SQL con sqlalchemy\n",
    "engine = create_engine(f\"postgresql://{user}:{password}@{host}/{db_name}\")\n",
    "\n",
    "# Iteramos en la lista de nombres de los 21 modelos\n",
    "for nombre_modelo in modelos_guardados:\n",
    "    # Extramos el nombre del vector objetivo separando por '_'.\n",
    "    # El caso de seeing_someone debe ser tratado especialmente\n",
    "    nombre_vector_objetivo = nombre_modelo.split('_')[0]\n",
    "    nombre_vector_objetivo = 'seeing_someone' if nombre_vector_objetivo == 'seeing' else nombre_vector_objetivo\n",
    "    # A partir del nombre cargamos el modelo\n",
    "    path_modelo = Path(\"./Modelos\")  / nombre_modelo\n",
    "    model = pickle.load(open(path_modelo, 'rb')) \n",
    "    # Iteramos en cada uno de los groups by que se hacen\n",
    "    for i, group in enumerate(lista_groups):\n",
    "        # El nombre de la tabla en SQL será un correlativo de la query más el nombre del modelo sin .sav\n",
    "        nombre_tabla_sql = f'query_{i + 1}_{nombre_modelo[:-4]}'\n",
    "        df_grouped = create_grouped_probabilty(model, X_test, nombre_vector_objetivo, group)\n",
    "        df_grouped.to_sql(\n",
    "            nombre_tabla_sql,\n",
    "            con=engine,\n",
    "            if_exists=\"replace\",\n",
    "            chunksize=1000,\n",
    "            method=\"multi\",\n",
    "            index=True # Por defecto True. Si no se quiere generar columna con el índice, asignar False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae99d1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0446e0",
   "metadata": {},
   "source": [
    "### sanity check: revisión rendimiento modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ea39d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos un diccionario con los 3 vectores objetivo\n",
    "dict_vect_obj_test = {\n",
    "    'single': y_test_single,\n",
    "    'seeing_someone': y_test_seeing_someone,\n",
    "    'available': y_test_available\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed9ff13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisaremos f1_score para cada uno del os modelos\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score_list_class_0 = []\n",
    "f1_score_list_class_1 = []\n",
    "f1_score_weighted_list = []\n",
    "f1_score_macro_list = []\n",
    "\n",
    "\n",
    "for nombre_modelo in modelos_guardados:\n",
    "    # Extraemos el nombre del vector objetivo a partir del nombre del modelo\n",
    "    nombre_vector_objetivo = nombre_modelo.split('_')[0]\n",
    "    nombre_vector_objetivo = 'seeing_someone' if nombre_vector_objetivo == 'seeing' else nombre_vector_objetivo\n",
    "    # Obtenemos la serie del vector objetivo\n",
    "    y_test = dict_vect_obj_test[nombre_vector_objetivo]\n",
    "    # Con la ruta, cargamos el modelo y predecimos y (el mismo que y_test)\n",
    "    path_modelo = Path(\"./Modelos\")  / nombre_modelo\n",
    "    model = pickle.load(open(path_modelo, 'rb'))     \n",
    "    y_predict = model.predict(X_test)\n",
    "    # Extraemos las métricas con f1\n",
    "    f1_score_aux = f1_score(y_test, y_predict, labels = [0, 1], average = None)\n",
    "    f1_score_list_class_0.append(f1_score_aux[0])\n",
    "    f1_score_list_class_1.append(f1_score_aux[1])\n",
    "    f1_score_weighted_list.append(f1_score(y_test, y_predict, average = 'weighted'))\n",
    "    f1_score_macro_list.append(f1_score(y_test, y_predict, average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5619f8af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_class0</th>\n",
       "      <th>f1_class1</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>f1_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>single_GradientBoostingClassifier.sav</th>\n",
       "      <td>0.048406</td>\n",
       "      <td>0.957792</td>\n",
       "      <td>0.884104</td>\n",
       "      <td>0.503099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seeing_someone_GradientBoostingClassifier.sav</th>\n",
       "      <td>0.980028</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.941698</td>\n",
       "      <td>0.490014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>available_GradientBoostingClassifier.sav</th>\n",
       "      <td>0.980002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.941673</td>\n",
       "      <td>0.490001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>single_RandomForestClassifier.sav</th>\n",
       "      <td>0.030321</td>\n",
       "      <td>0.956433</td>\n",
       "      <td>0.881389</td>\n",
       "      <td>0.493377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seeing_someone_RandomForestClassifier.sav</th>\n",
       "      <td>0.979689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.941372</td>\n",
       "      <td>0.489844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>available_RandomForestClassifier.sav</th>\n",
       "      <td>0.979715</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.941397</td>\n",
       "      <td>0.489858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>single_AdaBoostClassifier.sav</th>\n",
       "      <td>0.028504</td>\n",
       "      <td>0.957175</td>\n",
       "      <td>0.881924</td>\n",
       "      <td>0.492839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seeing_someone_AdaBoostClassifier.sav</th>\n",
       "      <td>0.980054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.941723</td>\n",
       "      <td>0.490027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>available_AdaBoostClassifier.sav</th>\n",
       "      <td>0.980054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.941723</td>\n",
       "      <td>0.490027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>single_LogisticRegression.sav</th>\n",
       "      <td>0.037803</td>\n",
       "      <td>0.957348</td>\n",
       "      <td>0.882837</td>\n",
       "      <td>0.497575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seeing_someone_LogisticRegression.sav</th>\n",
       "      <td>0.980054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.941723</td>\n",
       "      <td>0.490027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>available_LogisticRegression.sav</th>\n",
       "      <td>0.980054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.941723</td>\n",
       "      <td>0.490027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>single_BernoulliNB.sav</th>\n",
       "      <td>0.082847</td>\n",
       "      <td>0.954556</td>\n",
       "      <td>0.883921</td>\n",
       "      <td>0.518701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seeing_someone_BernoulliNB.sav</th>\n",
       "      <td>0.979556</td>\n",
       "      <td>0.004981</td>\n",
       "      <td>0.941439</td>\n",
       "      <td>0.492269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>available_BernoulliNB.sav</th>\n",
       "      <td>0.979556</td>\n",
       "      <td>0.004981</td>\n",
       "      <td>0.941439</td>\n",
       "      <td>0.492269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>single_DecisionTreeClassifier.sav</th>\n",
       "      <td>0.169869</td>\n",
       "      <td>0.917867</td>\n",
       "      <td>0.857256</td>\n",
       "      <td>0.543868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seeing_someone_DecisionTreeClassifier.sav</th>\n",
       "      <td>0.954718</td>\n",
       "      <td>0.073197</td>\n",
       "      <td>0.920240</td>\n",
       "      <td>0.513957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>available_DecisionTreeClassifier.sav</th>\n",
       "      <td>0.953569</td>\n",
       "      <td>0.068638</td>\n",
       "      <td>0.918958</td>\n",
       "      <td>0.511103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>single_SVC.sav</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.957774</td>\n",
       "      <td>0.880164</td>\n",
       "      <td>0.478887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seeing_someone_SVC.sav</th>\n",
       "      <td>0.980054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.941723</td>\n",
       "      <td>0.490027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>available_SVC.sav</th>\n",
       "      <td>0.980054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.941723</td>\n",
       "      <td>0.490027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               f1_class0  f1_class1  \\\n",
       "single_GradientBoostingClassifier.sav           0.048406   0.957792   \n",
       "seeing_someone_GradientBoostingClassifier.sav   0.980028   0.000000   \n",
       "available_GradientBoostingClassifier.sav        0.980002   0.000000   \n",
       "single_RandomForestClassifier.sav               0.030321   0.956433   \n",
       "seeing_someone_RandomForestClassifier.sav       0.979689   0.000000   \n",
       "available_RandomForestClassifier.sav            0.979715   0.000000   \n",
       "single_AdaBoostClassifier.sav                   0.028504   0.957175   \n",
       "seeing_someone_AdaBoostClassifier.sav           0.980054   0.000000   \n",
       "available_AdaBoostClassifier.sav                0.980054   0.000000   \n",
       "single_LogisticRegression.sav                   0.037803   0.957348   \n",
       "seeing_someone_LogisticRegression.sav           0.980054   0.000000   \n",
       "available_LogisticRegression.sav                0.980054   0.000000   \n",
       "single_BernoulliNB.sav                          0.082847   0.954556   \n",
       "seeing_someone_BernoulliNB.sav                  0.979556   0.004981   \n",
       "available_BernoulliNB.sav                       0.979556   0.004981   \n",
       "single_DecisionTreeClassifier.sav               0.169869   0.917867   \n",
       "seeing_someone_DecisionTreeClassifier.sav       0.954718   0.073197   \n",
       "available_DecisionTreeClassifier.sav            0.953569   0.068638   \n",
       "single_SVC.sav                                  0.000000   0.957774   \n",
       "seeing_someone_SVC.sav                          0.980054   0.000000   \n",
       "available_SVC.sav                               0.980054   0.000000   \n",
       "\n",
       "                                               f1_weighted  f1_macro  \n",
       "single_GradientBoostingClassifier.sav             0.884104  0.503099  \n",
       "seeing_someone_GradientBoostingClassifier.sav     0.941698  0.490014  \n",
       "available_GradientBoostingClassifier.sav          0.941673  0.490001  \n",
       "single_RandomForestClassifier.sav                 0.881389  0.493377  \n",
       "seeing_someone_RandomForestClassifier.sav         0.941372  0.489844  \n",
       "available_RandomForestClassifier.sav              0.941397  0.489858  \n",
       "single_AdaBoostClassifier.sav                     0.881924  0.492839  \n",
       "seeing_someone_AdaBoostClassifier.sav             0.941723  0.490027  \n",
       "available_AdaBoostClassifier.sav                  0.941723  0.490027  \n",
       "single_LogisticRegression.sav                     0.882837  0.497575  \n",
       "seeing_someone_LogisticRegression.sav             0.941723  0.490027  \n",
       "available_LogisticRegression.sav                  0.941723  0.490027  \n",
       "single_BernoulliNB.sav                            0.883921  0.518701  \n",
       "seeing_someone_BernoulliNB.sav                    0.941439  0.492269  \n",
       "available_BernoulliNB.sav                         0.941439  0.492269  \n",
       "single_DecisionTreeClassifier.sav                 0.857256  0.543868  \n",
       "seeing_someone_DecisionTreeClassifier.sav         0.920240  0.513957  \n",
       "available_DecisionTreeClassifier.sav              0.918958  0.511103  \n",
       "single_SVC.sav                                    0.880164  0.478887  \n",
       "seeing_someone_SVC.sav                            0.941723  0.490027  \n",
       "available_SVC.sav                                 0.941723  0.490027  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        'f1_class0': f1_score_list_class_0,\n",
    "        'f1_class1': f1_score_list_class_1,\n",
    "        'f1_weighted': f1_score_weighted_list,\n",
    "        'f1_macro': f1_score_macro_list  \n",
    "    },\n",
    "    index = modelos_guardados,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a86943f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad single: 18327\n",
      "Cantidad seeing_someone: 780\n",
      "Cantidad available: 780\n",
      "Cantidad total: 19943\n"
     ]
    }
   ],
   "source": [
    "# Revisamos la cantidad de valores 1 y 0 por cada vector objetivo\n",
    "print(f'Cantidad single: {y_test_single.sum()}')\n",
    "print(f'Cantidad seeing_someone: {y_test_seeing_someone.sum()}')\n",
    "print(f'Cantidad available: {y_test_available.sum()}')\n",
    "print(f'Cantidad total: {y_test_single.count()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103b3e0d",
   "metadata": {},
   "source": [
    "Si bien no es el objetivo del notebook, se extraen métricas de rendimiento para los modelos. Se observa que el F1 es mejor siempre en la clase mayoritaria, ya que estamos en un caso en que los 3 vectores objetivos están muy desbalanceados.  \n",
    "\n",
    "Single tiene muchas observaciones, de modo que el F1 de la clase single = 1 es muy bueno. Sin embargo, single = 0 no tiene un buen rendimiento. Los otros dos vectores objetivos tienen el comportamiento contrario, son muy buenos para la clase 0, que es la mayoritaria.  \n",
    "\n",
    "Este mal comportamiento se evidencia en el macro avg, el cual castiga más las observaciones mal clasificadas de la categoría minoritaria."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
